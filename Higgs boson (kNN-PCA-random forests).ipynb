{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e288e50e",
   "metadata": {},
   "source": [
    "### This Program tries to predict whether a particle is a Higgs boson based on collision data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b66cb8",
   "metadata": {},
   "source": [
    "The data set comes from Hugging face: https://huggingface.co/datasets/mstz/higgs and we compare our performances with the ones published in the following article : https://www.nature.com/articles/ncomms5308/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn import neighbors, metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import ensemble\n",
    "\n",
    "from multiprocessing import cpu_count  # define this in order to run some computations in parallel\n",
    "n_cpu = cpu_count()-1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69eeb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/higgs.csv')\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239bc08f",
   "metadata": {},
   "source": [
    "This warning means that some columns have data of different types. Let us look at the shape of the data frame and fetch the name of the problematic columns.\n",
    "\n",
    "\n",
    "\n",
    "We will therefore convert all data to floats. \n",
    "If the data is of string type that can't be converted, the argument 'coerce' will convert them to NaN.\n",
    "\n",
    "We then drop all rows that have a NaN. The argument 'inplace' modifies the dataframe without creating a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be757bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['jet4phi', 'jet4b-tag', 'm_jj', 'm_jjj', 'm_lv', ' m_jlv', 'm_bb', 'm_wbb', 'm_wwbb']:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c40a8d2847145",
   "metadata": {},
   "source": [
    "We see that there was just one problematic row and we got rid of it. \n",
    "\n",
    "100 000 rows is high. For most of the training I used a 10% sample. \n",
    "Here I put frac=1 because in what follows I chose all my models and hyperparameters, so I want to use the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ada73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df.sample(frac=1, random_state=77) \n",
    "# the fixed random_state is for reproducibility purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc4848",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(df_reduced.columns)  # creates a list with the name of all the columns\n",
    "target = feature_names.pop(0)  # creates our target variable and removes it from the features list\n",
    "n_features = len(feature_names) #number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a23d7b",
   "metadata": {},
   "source": [
    "Let us do some data visualisation on our features. There's around 30 columns so let us display all of them at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de23bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the function multiplot that plots all our features at once for a given data set.\n",
    "\n",
    "def multiplot(data, n_plot):\n",
    "    n_cols = 5  # number of columns we want to display\n",
    "    n_rows = (n_plot + n_cols - 1) // n_cols  # This line calculates the number of rows needed for the grid. \n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "\n",
    "    for idx, column in enumerate(feature_names):\n",
    "       ax = axes[idx // n_cols, idx % n_cols]\n",
    "       ax.hist(data[column], bins=50)\n",
    "       ax.set_title(column)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplot(df_reduced, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0390e21",
   "metadata": {},
   "source": [
    "We see that some features are uniformly distributed, some are gaussian and some are sparse. \n",
    "We notice that a few features have a thin but long tail like 'm_jj' and 'm_jjj', which could be a problem in the case of KNN.\n",
    "Indeed a few outliers means that after scaling, the majority of the data of such features will be squashed, and hence this feature will essentially be useless for most data except for outliers. \n",
    "The way we deal with this here is by applying a logarithm before scaling because for all of our features with tails, the data is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1662a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced['m_jj'] = df['m_jj'].apply(np.log10)\n",
    "df_reduced['m_jjj'] = df['m_jjj'].apply(np.log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a7a148",
   "metadata": {},
   "source": [
    "We now select the features we are interested in (here I kept everything), and we want to predict Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95da7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features= ['lepton_pT', 'lepton_eta', 'lepton_phi','missing_energy_magnitude', 'missing_energy_phi', 'jet1pt', 'jet1eta','jet1phi', 'jet1b-tag', 'jet2pt', 'jet2eta', 'jet2phi', 'jet2b-tag','jet3pt', 'jet3eta', 'jet3phi', 'jet3b-tag', 'jet4pt', 'jet4eta','jet4phi', 'jet4b-tag', 'm_jj', 'm_jjj', 'm_lv', ' m_jlv', 'm_bb','m_wbb', 'm_wwbb']\n",
    "X=df_reduced[features]\n",
    "Y=df_reduced['is_boson']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170e33d",
   "metadata": {},
   "source": [
    "Our target is \"is_boson\" saying whether or not a colission produced a Higgs boson. \n",
    "Let us check that the target is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f24882",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_frequencies = df_reduced[target].value_counts(normalize='true')\n",
    "bars = plt.bar(target_frequencies.index, target_frequencies.values, color=['tab:blue', 'tab:green'])\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks([0, 1])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2, height + 0.01, \n",
    "        f'{height:.2%}', ha='center', va='bottom',\n",
    "    )\n",
    "plt.ylim([0, 0.6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd2c252",
   "metadata": {},
   "source": [
    "We see that our target is pretty balanced, moreover it could give us a naive baseline for the minimal accuracy our model needs to have.\n",
    "\n",
    "Let us start with a KNN algorithm. First thing to do is normalizing the data, meaning we want columns to have a mean of 0 and a standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f49e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "X_standardized = pd.DataFrame(X_standardized, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc23611",
   "metadata": {},
   "source": [
    "We check that our data is indeed scaled as wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbe730",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplot(X_standardized, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1400807",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X_standardized, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the values of hyperparameters we want to test.\n",
    "param_grid = {'n_neighbors':list(range(35, 46))}\n",
    "\n",
    "# We choose a score to optimise, here it will be the roc_auc (area under the ROC curve, check literature for details)\n",
    "# We choose this score because it's the one chosen from the paper so that we can compare performances.\n",
    "score = 'roc_auc'\n",
    "\n",
    "# We create a kNN classifier who searches for hyperparameters by crossed validation\n",
    "clf = model_selection.GridSearchCV(\n",
    "    neighbors.KNeighborsClassifier(), # kNN classifier\n",
    "    param_grid,     # the hyperparameters to test that we defined above\n",
    "    cv=5,           # number of cross-validation folds\n",
    "    scoring=score,   # score to optimize\n",
    "    n_jobs=n_cpu    # number of CPUs to use in parallel to speed up\n",
    ")\n",
    "\n",
    "# We fit the models on our training set\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# We print the optimal hyperparameters\n",
    "print(\"Best hyperparameters on training set:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "# We print the corresponding performances\n",
    "print(\"Cross Validation results:\")\n",
    "for mean, std, params in zip(\n",
    "        clf.cv_results_['mean_test_score'], # mean score\n",
    "        clf.cv_results_['std_test_score'],  # score standard deviation\n",
    "        clf.cv_results_['params']           # value of the hyperparameter\n",
    "    ):\n",
    "\n",
    "    print(\"{} = {:.3f} (+/-{:.03f}) for {}\".format(\n",
    "        score,\n",
    "        mean,\n",
    "        std*2,\n",
    "        params\n",
    "    ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec1c08",
   "metadata": {},
   "source": [
    "Various values of the hyperparameter k have been tested. The optimum was always near $k$=40. \n",
    "When keeping 10% of the data set the roc_auc was around 0.66. On the full data set, the accuracy is around 0.70. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f5d493",
   "metadata": {},
   "source": [
    "Here we kept all features (around 30).\n",
    "Maybe that's too many features. \n",
    "In order to counteract the curse of dimensionality,\n",
    "we now attempt to do a PCA in order to keep only the most relevant features, in order to improve our performance. \n",
    "\n",
    "caveat: as explained in the scientific paper, our problem is in fact non-linear with respect to the features. \n",
    "We therefore have reasons to believe that the PCA will perform poorly. \n",
    "We carry on regardless for pedagogical purposes. \n",
    "One way to improve would be instead to do a feature selection based on a \"mutual information\" method which can work in the non-linear case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf0a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()  # I didn't specify n_components because I don't know how many I want to retain yet.\n",
    "pca.fit(X_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e2a8bc",
   "metadata": {},
   "source": [
    "Technically I should do the pca on the train set and not on the whole set to make sure we can generalize accurately. \n",
    "This would be tedious in our case as we would need to implement the cross validation and the pca at the same time (could be done using a pipeline).\n",
    "Here, we will just assume that there's not distribution shift and we will carry on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5590be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "scree = (pca.explained_variance_ratio_*100)\n",
    "scree.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b19a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scree_cum = scree.cumsum()\n",
    "scree_cum.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d487ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = list(range(1, n_features+1))\n",
    "plt.bar(x_list, scree)\n",
    "plt.plot(x_list, scree_cum,c=\"red\",marker='o')\n",
    "plt.xlabel(\"rank of inertia axis\")\n",
    "plt.ylabel(\"inertia percentage\")\n",
    "plt.title(\"scree plot of eigenvalues\")\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f19bb",
   "metadata": {},
   "source": [
    "According to the elbow method, I should only keep the first component, which explains only 14% of the variance. We can already see that our PCA is not promising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c95c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207dc7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 0, 1  # Defining our axes\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "for i in range(0, pca.components_.shape[1]):\n",
    "    ax.arrow(0,\n",
    "             0,  # Start the arrow at the origin\n",
    "             pca.components_[0, i],  #0 for PC1\n",
    "             pca.components_[1, i],  #1 for PC2\n",
    "             head_width=0.07,\n",
    "             head_length=0.07, \n",
    "             width=0.02,              \n",
    "    )  \n",
    "\n",
    "    plt.text(pca.components_[0, i] + 0.05,\n",
    "             pca.components_[1, i] + 0.05,\n",
    "             features[i])\n",
    "    \n",
    "# display horizontal and vertical lines\n",
    "plt.axvline(x=0, ymin=-1, ymax=1, color='grey', ls='--')\n",
    "plt.axhline(y=0, xmin=-1, xmax=1, color='grey', ls='--')\n",
    "\n",
    "# name of axes, with the associated percentage of inertia\n",
    "plt.xlabel('F{} ({}%)'.format(x+1, round(100*pca.explained_variance_ratio_[x],1)))\n",
    "plt.ylabel('F{} ({}%)'.format(y+1, round(100*pca.explained_variance_ratio_[y],1)))\n",
    "\n",
    "plt.title(\"Correlation circle (F{} et F{})\".format(x+1, y+1))\n",
    "\n",
    "\n",
    "an = np.linspace(0, 2 * np.pi, 100)\n",
    "plt.plot(np.cos(an), np.sin(an))  # Add a unit circle for scale\n",
    "plt.axis('equal')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce13e2",
   "metadata": {},
   "source": [
    "We can see that some features are indeed correlated but none of the arrows are very long, they are now well represented by our new components as we expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj = pca.transform(X_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e3d65",
   "metadata": {},
   "source": [
    "We conclude that it is unclear how many components we want to keep. We will therefore treat the number of components to keep as a hyperparameter: n_components and test every choice with $k$ the number of neighbors in the kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_components in [25]:\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_standardized)\n",
    "    X_proj = pca.transform(X_standardized)\n",
    "    X_train_temp, X_test_temp, Y_train_temp, Y_test_temp = model_selection.train_test_split(X_proj, Y, test_size=0.2)\n",
    "    \n",
    "    # Fix the values of hyperparameters we want to test.\n",
    "    param_grid = {'n_neighbors':[50]}\n",
    "\n",
    "    # We choose a score to optimise, here it will be the accuracy (meaning the proportion of correct predictions)\n",
    "    score = 'roc_auc'\n",
    "\n",
    "    # We create a kNN classifier who searches for hyperparameters by crossed validation\n",
    "    clf = model_selection.GridSearchCV(\n",
    "        neighbors.KNeighborsClassifier(), # kNN classifier\n",
    "        param_grid,     # the hyperparameters to test that we defined above\n",
    "        cv=5,           # number of cross-validation folds\n",
    "        scoring=score   # score to optimize\n",
    "    )\n",
    "\n",
    "    # We fit the models on our training set\n",
    "    clf.fit(X_train_temp, Y_train_temp)\n",
    "\n",
    "    # We print the optimal hyperparameters\n",
    "    print(\"Best hyperparameters on training set:\")\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    # We print the corresponding performances\n",
    "    print(\"Cross validation results:\")\n",
    "    for mean, std, params in zip(\n",
    "            clf.cv_results_['mean_test_score'], # mean score\n",
    "            clf.cv_results_['std_test_score'],  # score standard deviation\n",
    "            clf.cv_results_['params']           # value of the hyperparameter\n",
    "            ):\n",
    "\n",
    "        print(\"{} = {:.3f} (+/-{:.03f}) for {}\".format(\n",
    "            score,\n",
    "            mean,\n",
    "            std*2,\n",
    "            params\n",
    "        ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f35c20b",
   "metadata": {},
   "source": [
    "I tested on many hyperparameters for 10% of the data. The optimum was for k=50 and C=25. \n",
    "Our roc_auc=0.70, which is exactly the same as the kNN without PCA. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec41d93",
   "metadata": {},
   "source": [
    "As explained above we expected the PCA to not perform well and it is indeed the case. In order to improve our performance, we try another model and turn to random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64469dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [1000],\n",
    "    'max_depth': [20],\n",
    "    \n",
    "}\n",
    "\n",
    "# We choose a score to optimise, here we pick roc_auc to compare with the paper\n",
    "score = 'roc_auc'\n",
    "\n",
    "# We create a kNN classifier who searches for hyperparameters by crossed validation\n",
    "clf = model_selection.GridSearchCV(\n",
    "    ensemble.RandomForestClassifier(n_jobs=n_cpu), # random forest classifier\n",
    "    param_grid,     # the hyperparameters to test that we defined above\n",
    "    cv=5,           # number of cross-validation folds\n",
    "    scoring=score, # score to optimize\n",
    "    n_jobs=n_cpu\n",
    ")\n",
    "\n",
    "# We fit the models on our training set\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# We print the optimal hyperparameters\n",
    "print(\"Best hyperparameters on training set:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "# We print the corresponding performances\n",
    "print(\"Cross validation results:\")\n",
    "for mean, std, params in zip(\n",
    "        clf.cv_results_['mean_test_score'], # mean score\n",
    "        clf.cv_results_['std_test_score'],  # score standard deviation\n",
    "        clf.cv_results_['params']           # value of the hyperparameter\n",
    "    ):\n",
    "\n",
    "    print(\"{} = {:.3f} (+/-{:.03f}) for {}\".format(\n",
    "        score,\n",
    "        mean,\n",
    "        std*2,\n",
    "        params\n",
    "    ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e6e318",
   "metadata": {},
   "source": [
    "(took some time, if want to rerun do it with chosen hyperparameters).\n",
    "\n",
    "After several rounds of exploring hyperparameters (number of trees and depth of forest), We get a roc_auc of around 0.80.\n",
    "We can compare with the performance obtained in the paper page 7. For a boosted decision tree and shallow neural network, performance is around 0.81 when keeping all features, so we almost reproduced the performance from the paper. In order to improve further the performance, they used deep neural networks.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
